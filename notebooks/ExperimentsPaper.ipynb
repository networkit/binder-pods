{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "import seaborn\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to true for experiments on directed graphs, to false for experiments on undirected graphs\n",
    "isDirected = True\n",
    "\n",
    "undirected = [\"Mus_musculus.txt.graph\",\"HC-BIOGRID.txt.graph\",\"Caenorhabditis_elegans.txt.graph\",\"ca-GrQc.txt.graph\",\"advogato.txt.graph\",\"hprd_pp.txt.graph\",\n",
    "\"ca-HepTh.txt.graph\",\"Drosophila_melanogaster.txt.graph\",\"oregon1_010526.txt.graph\",\"oregon2_010526.txt.graph\",\"Homo_sapiens.txt.graph\",\"GoogleNw.txt.graph\",\n",
    "\"CA-CondMat.txt\"]\n",
    "\n",
    "directed = [\"out.subelj_jung-j_jung-j.graph\", \"wiki-Vote.txt.graph\", \"out.elec.graph\", \"freeassoc.txt.graph\",  \n",
    "\"out.dblp-cite.graph\", \"out.subelj_cora_cora.graph\", \"out.ego-twitter.graph\",  \"out.ego-gplus.graph\",\n",
    "\"out.munmun_digg_reply.graph\"]\n",
    "\n",
    "labelsUndirected = [\"Mus-musculus\",\"HC-BIOGRID\",\"Caenor-eleg\",\"ca-GrQc\",\"advogato\",\"hprd-pp\",\n",
    "    \"ca-HepTh\",\"dr-melanog\",\"oregon1\",\"oregon2\",\"Homo-sapiens\",\"GoogleNw\",\"CA-CondMat\"]\n",
    "\n",
    "labelsDirected = [\"subelj-jung\", \"wiki-Vote\", \"elec\", \"freeassoc\", \"dblp-cite\", \"subelj-cora\", \"ego-twitter\", \"ego-gplus\",\n",
    "         \"munmun-digg\"]\n",
    "\n",
    "pathUndirected = \"../scripts/resultsCompUndirected/results_\"\n",
    "pathDirected = \"../scripts/resultsCompDirected/results_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgTimes(graphs, path, labels):\n",
    "    # compute average times and std deviations\n",
    "    # table 2 and 3 (depending on graphs and path)\n",
    "    avgDyn = {}\n",
    "    avgStat = {}\n",
    "    avgDynOne = {}\n",
    "    devDyn = {}\n",
    "    devStat = {}\n",
    "    devDynOne = {}\n",
    "\n",
    "\n",
    "    for g in graphs:\n",
    "        file = path+g+\".csv\"\n",
    "        table = pd.read_csv(file)\n",
    "        timesDyn = list(table[\"Dyn\"])\n",
    "        timesDynOne = list(table[\"Dyn One Node\"])\n",
    "        timesStat = list(table[\"Static bc\"])\n",
    "        avgDyn[g] = '{0:.4f}'.format(scipy.average(timesDyn))\n",
    "        avgDynOne[g] = '{0:.4f}'.format(scipy.average(timesDynOne))\n",
    "        avgStat[g] = '{0:.2f}'.format(scipy.average(timesStat))\n",
    "        devDyn[g] = '{0:.4f}'.format(scipy.std(timesDyn))\n",
    "        devDynOne[g] = '{0:.4f}'.format(scipy.std(timesDynOne))\n",
    "        devStat[g] = '{0:.4f}'.format(scipy.std(timesStat))\n",
    "\n",
    "    for i, g in enumerate(graphs):\n",
    "        print(\"\\\\texttt{\" + labels[i] + \"} \\t & \\t\" + str(avgStat[g])+\"\\t & \\t\"+str(avgDyn[g])+\"\\t & \\t \\\\textbf{\"+str(avgDynOne[g])+\n",
    "              \"}\\t & \\t\"+str(devDyn[g])+\"\\t & \\t\"+str(devDynOne[g])+\" \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print table 2 and table 3\n",
    "#print(\"Results for directed graphs\")\n",
    "#avgTimes(directed, pathDirected, labelsDirected)\n",
    "print(\"\\n\\nResults for undirected graphs\\n\")\n",
    "avgTimes(undirected, pathUndirected, labelsUndirected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSpeedups(graphs, path, labels):\n",
    "# now we print the geometric mean of the speedups on static recomputation and on the dynamic algo for all nodes, \n",
    "# the maximum and the minimum speedup (table 4 and 5)\n",
    "    speedOnStat = {}\n",
    "    speedOnDyn = {}\n",
    "    maxSpeedOnStat = {}\n",
    "    maxSpeedOnDyn = {}\n",
    "    minSpeedOnStat = {}\n",
    "    minSpeedOnDyn = {}\n",
    "\n",
    "    for g in graphs:\n",
    "        file = path+g+\".csv\"\n",
    "        table = pd.read_csv(file)\n",
    "        nSamples = len(table)\n",
    "        timesDyn = []\n",
    "        timesDynOne = []\n",
    "        timesStat = []\n",
    "        for i in range(nSamples):\n",
    "            timesDyn.append(table[\"Dyn\"][i])\n",
    "            timesDynOne.append(table[\"Dyn One Node\"][i])\n",
    "            timesStat.append(table[\"Static bc\"][i])\n",
    "        speedOnStat[g] = '{0:.1f}'.format(stats.gmean([timesStat[i]/timesDynOne[i] for i in range(len(timesDynOne))]))\n",
    "        speedOnDyn[g] = '{0:.1f}'.format(stats.gmean([timesDyn[i]/timesDynOne[i] for i in range(len(timesDynOne))]))\n",
    "        maxSpeedOnStat[g] = '{0:.1f}'.format(max([timesStat[i]/timesDynOne[i] for i in range(len(timesDynOne))]))\n",
    "        maxSpeedOnDyn[g] = '{0:.1f}'.format(max([timesDyn[i]/timesDynOne[i] for i in range(len(timesDynOne))]))\n",
    "        minSpeedOnStat[g] = '{0:.1f}'.format(min([timesStat[i]/timesDynOne[i] for i in range(len(timesDynOne))]))\n",
    "        minSpeedOnDyn[g] = '{0:.1f}'.format(min([timesDyn[i]/timesDynOne[i] for i in range(len(timesDynOne))]))\n",
    "\n",
    "    for i, g in enumerate(graphs):\n",
    "        print(\"\\\\texttt{\" + labels[i] + \"} \\t & \\t\" + speedOnStat[g]+\"\\t & \\t\"+maxSpeedOnStat[g]+\"\\t & \\t\"+minSpeedOnStat[g]+\"\\t & \\t\"+speedOnDyn[g]+\n",
    "              \"\\t & \\t\"+maxSpeedOnDyn[g]+\"\\t & \\t\"+minSpeedOnDyn[g]+\" \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print table 4 and table 5\n",
    "print(\"Results for directed graphs\")\n",
    "printSpeedups(directed, pathDirected, labelsDirected)\n",
    "print(\"\\n\\nResults for undirected graphs\\n\")\n",
    "printSpeedups(undirected, pathUndirected, labelsUndirected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 13, 14 (change g to see different graphs)\n",
    "# set zoom to 0 for no zoom, or to a specific value to zoom in the interval [0, zoom] in the y axis\n",
    "def showAffected(g, path, zoom):\n",
    "    file = path+g+\".csv\"\n",
    "    table = pd.read_csv(file)\n",
    "\n",
    "\n",
    "    # we sort by affected nodes\n",
    "    dyn = [(table[\"Affected\"][i], table[\"Dyn\"][i]) for i in range(len(table[\"Affected\"]))]\n",
    "    dyn.sort()\n",
    "    dynOne = [(table[\"Affected\"][i], table[\"Dyn One Node\"][i]) for i in range(len(table[\"Affected\"]))]\n",
    "    dynOne.sort()\n",
    "\n",
    "    x = [dyn[i][0] for i in range(len(dyn))]\n",
    "    y1 = [dyn[i][1] for i in range(len(dyn))]\n",
    "    y2 = [dynOne[i][1] for i in range(len(dynOne))]\n",
    "    y3 = list(table[\"Static bc\"])\n",
    "\n",
    "    # plot\n",
    "    f, ax = plt.subplots(1, 1)\n",
    "\n",
    "    np.random.seed(8)\n",
    "    mean, cov = [4, 6], [(1.5, .7), (.7, 1)]\n",
    "    x = array(x)\n",
    "    y1 = array(y1)\n",
    "    y2 = array(y2)\n",
    "    seaborn.regplot(x=x, y=y1, color=\"r\", label=\"AI\")\n",
    "    seaborn.regplot(x=x, y=y2, color=\"b\", label=\"SI\")\n",
    "    ax.legend((\"AI\", \"SI\"), fontsize = 10)\n",
    "    xlabel('Affected pairs')\n",
    "    ylabel('Time [s]')\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "                 ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(10)\n",
    "\n",
    "    xlim(0, max(x))\n",
    "    if zoom > 0:\n",
    "        ylim(0, zoom)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 13 (top left)\n",
    "showAffected(directed[7], pathDirected, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 13 (bottom left)\n",
    "showAffected(directed[7], pathDirected, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 13 (top right)\n",
    "showAffected(directed[8], pathDirected, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 13 (bottom right)\n",
    "showAffected(directed[8], pathDirected, 5.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 14 (top left)\n",
    "showAffected(undirected[7], pathUndirected, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 14 (bottom left)\n",
    "showAffected(undirected[7], pathUndirected, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 14 (top right)\n",
    "showAffected(undirected[10], pathUndirected, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 14 (bottom right)\n",
    "showAffected(undirected[7], pathUndirected, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison with other heuristics (Figures 7 - 12)\n",
    "# we first read the necessary data \n",
    "    \n",
    "def readDataHeuristics(file):\n",
    "    f = open(file, \"r\")\n",
    "    init_scores = {}\n",
    "    init_ranks = {}\n",
    "    scores_greedy = {}\n",
    "    ranks_greedy = {}\n",
    "    scores_bc = {}\n",
    "    ranks_bc = {}\n",
    "    scores_deg = {}\n",
    "    ranks_deg = {}\n",
    "    scores_rand = {}\n",
    "    ranks_rand = {}\n",
    "    nodes = {}\n",
    "    edges = {}\n",
    "    current = \"x\"\n",
    "    sample = 0\n",
    "    for line in f:\n",
    "        if line.startswith(\"Graph,\"):\n",
    "            continue\n",
    "        if line.startswith(\"Graph:\"):\n",
    "            graph = line.split(\",\")[0].split(\":\")[1].strip()\n",
    "            if graph != current:\n",
    "                init_scores[graph] = [[]]\n",
    "                init_ranks[graph] = [[]]\n",
    "                scores_greedy[graph] = [[]]\n",
    "                ranks_greedy[graph] = [[]]\n",
    "                scores_bc[graph] = [[]]\n",
    "                ranks_bc[graph] = [[]]\n",
    "                scores_deg[graph] = [[]]\n",
    "                ranks_deg[graph] = [[]]\n",
    "                scores_rand[graph] = [[]]\n",
    "                ranks_rand[graph] = [[]]\n",
    "                current = graph\n",
    "                sample = 0\n",
    "            else:\n",
    "                sample += 1\n",
    "                init_scores[graph].append([])\n",
    "                init_ranks[graph].append([])\n",
    "                scores_greedy[graph].append([])\n",
    "                ranks_greedy[graph].append([])\n",
    "                scores_bc[graph].append([])\n",
    "                ranks_bc[graph].append([])\n",
    "                scores_deg[graph].append([])\n",
    "                ranks_deg[graph].append([])\n",
    "                scores_rand[graph].append([])\n",
    "                ranks_rand[graph].append([])\n",
    "        else:\n",
    "            fields = line.split(\",\")\n",
    "            nodes[graph] = float(fields[1])\n",
    "            edges[graph] = float(fields[2])\n",
    "            init_scores[graph][sample].append(float(fields[3]))\n",
    "            init_ranks[graph][sample].append(float(fields[4]))\n",
    "            scores_greedy[graph][sample].append(float(fields[5]))\n",
    "            ranks_greedy[graph][sample].append(float(fields[6]))\n",
    "            scores_deg[graph][sample].append(float(fields[7]))\n",
    "            ranks_deg[graph][sample].append(float(fields[8]))\n",
    "            scores_bc[graph][sample].append(float(fields[9]))\n",
    "            ranks_bc[graph][sample].append(float(fields[10]))\n",
    "            scores_rand[graph][sample].append(float(fields[11]))\n",
    "            ranks_rand[graph][sample].append(float(fields[12]))\n",
    "    return nodes, edges, init_scores, scores_greedy, scores_deg, scores_bc, scores_rand, init_ranks, ranks_greedy, ranks_deg, ranks_bc, ranks_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../scripts/resultsCompHeuristicsDirected.txt\"\n",
    "nodes, edges, init_scores, scores_greedy, scores_deg, scores_bc, scores_rand, init_ranks, ranks_greedy, ranks_deg, ranks_bc, ranks_rand = readDataHeuristics(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with betweenness of a single node for different values of k (one specific sample) -- Fig. 7 and 8\n",
    "\n",
    "def plotBCImprovement(graph, sample, init_scores, scores_greedy, scores_deg, scores_bc, scores_rand):\n",
    "    figure(figsize=(6,3))\n",
    "    x1 = array(range(0, 11))\n",
    "\n",
    "    y1 = array([init_scores[graph][sample][0]]+scores_greedy[graph][sample])\n",
    "\n",
    "    y2 = array([init_scores[graph][sample][0]]+scores_deg[graph][sample])\n",
    "    y3 = array([init_scores[graph][sample][0]]+scores_bc[graph][sample])\n",
    "    y4 = array([init_scores[graph][sample][0]]+scores_rand[graph][sample])\n",
    "\n",
    "    p1 = plot(x1, y1, 'ro')\n",
    "    p2 = plot(x1, y2, 'ro', color='#1B2ACC')\n",
    "    p3 = plot(x1, y3, 'ro', color='#1A2A11')\n",
    "    p4 = plot(x1, y4, 'ro', color='#AA21BB')\n",
    "    legend((p1[0], p2[0], p3[0], p4[0]), (\"Greedy\",\"Top-k Degree\", \"Top-k Betweenness\", \"Random\"), loc=\"best\")\n",
    "\n",
    "    xlim(-0.2, 10.2)\n",
    "    xlabel('k')\n",
    "    ylabel('Betweenness')\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 7 (left)\n",
    "graph = \"munmun_digg_reply\"\n",
    "sample = 0\n",
    "plotBCImprovement(graph, sample, init_scores, scores_greedy, scores_deg, scores_bc, scores_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 7 (right)\n",
    "graph = \"munmun_digg_reply\"\n",
    "sample = 1\n",
    "plotBCImprovement(graph, sample, init_scores, scores_greedy, scores_deg, scores_bc, scores_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8 (left)\n",
    "graph = \"linux\"\n",
    "sample = 0\n",
    "plotBCImprovement(graph, sample, init_scores, scores_greedy, scores_deg, scores_bc, scores_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 8 (right)\n",
    "graph = \"linux\"\n",
    "sample = 1\n",
    "plotBCImprovement(graph, sample, init_scores, scores_greedy, scores_deg, scores_bc, scores_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative results: given a graph, we compute the average betweenness over all samples\n",
    "def computeCumulativeResults(init_scores, scores_greedy, scores_deg, scores_bc, scores_rand):\n",
    "    avg_scores_greedy = {}\n",
    "    avg_scores_deg = {}\n",
    "    avg_scores_bc = {}\n",
    "    avg_scores_rand = {}\n",
    "    avg_init_scores = {}\n",
    "\n",
    "    for graph in scores_greedy:\n",
    "        avg_init_scores[graph] = []\n",
    "        avg_scores_greedy[graph] = []\n",
    "        avg_scores_deg[graph] = []\n",
    "        avg_scores_bc[graph] = []\n",
    "        avg_scores_rand[graph] = []\n",
    "        for k in range(10):\n",
    "            sumk = sum([init_scores[graph][sample][k] for sample in range(len(scores_greedy[graph]))])\n",
    "            sumk = sumk/float(len(scores_greedy[graph]))\n",
    "            avg_init_scores[graph].append(sumk)\n",
    "            sumk = sum([scores_greedy[graph][sample][k] for sample in range(len(scores_greedy[graph]))])\n",
    "            sumk = sumk/float(len(scores_greedy[graph]))\n",
    "            avg_scores_greedy[graph].append(sumk)\n",
    "            sumk = sum([scores_deg[graph][sample][k] for sample in range(len(scores_greedy[graph]))])\n",
    "            sumk = sumk/float(len(scores_greedy[graph]))\n",
    "            avg_scores_deg[graph].append(sumk)\n",
    "            sumk = sum([scores_bc[graph][sample][k] for sample in range(len(scores_greedy[graph]))])\n",
    "            sumk = sumk/float(len(scores_greedy[graph]))\n",
    "            avg_scores_bc[graph].append(sumk)\n",
    "            sumk = sum([scores_rand[graph][sample][k] for sample in range(len(scores_greedy[graph]))])\n",
    "            sumk = sumk/float(len(scores_greedy[graph]))\n",
    "            avg_scores_rand[graph].append(sumk)\n",
    "    return avg_scores_greedy, avg_scores_deg, avg_scores_bc, avg_scores_rand, avg_init_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBCImprovementCumulative(graph, nodes, edges, avg_scores_greedy, avg_scores_deg, avg_scores_bc, avg_scores_rand, avg_init_scores):\n",
    "    figure(figsize=(6,3))\n",
    "    x1 = array(range(0, 11))\n",
    "    y1 = array([avg_init_scores[graph][0]]+avg_scores_greedy[graph])\n",
    "    y2 = array([avg_init_scores[graph][0]]+avg_scores_deg[graph])\n",
    "    y3 = array([avg_init_scores[graph][0]]+avg_scores_bc[graph])\n",
    "    y4 = array([avg_init_scores[graph][0]]+avg_scores_rand[graph])\n",
    "    y1 = [score/(nodes[graph]*nodes[graph]-edges[graph])*100 for score in y1]\n",
    "    y2 = [score/(nodes[graph]*nodes[graph]-edges[graph])*100 for score in y2]\n",
    "    y3 = [score/(nodes[graph]*nodes[graph]-edges[graph])*100 for score in y3]\n",
    "    y4 = [score/(nodes[graph]*nodes[graph]-edges[graph])*100 for score in y4]\n",
    "\n",
    "    p1 = plot(x1, y1, 'ro')\n",
    "    p2 = plot(x1, y2, 'ro', color='#1B2ACC')\n",
    "    p3 = plot(x1, y3, 'ro', color='#1A2A11')\n",
    "    p4 = plot(x1, y4, 'ro', color='#AA21BB')\n",
    "    legend((p1[0], p2[0], p3[0], p4[0]), (\"Greedy\",\"Top-k Degree\", \"Top-k Betweenness\", \"Random\"), loc=\"best\")\n",
    "\n",
    "    xlim(-0.2, 10.2)\n",
    "    xlabel('k')\n",
    "    ylabel('Betweenness')\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 9 (left)\n",
    "\n",
    "avg_scores_greedy, avg_scores_deg, avg_scores_bc, avg_scores_rand, avg_init_scores = computeCumulativeResults(init_scores, scores_greedy, scores_deg, scores_bc, scores_rand)\n",
    "graph = 'munmun_digg_reply'\n",
    "plotBCImprovementCumulative(graph, nodes, edges, avg_scores_greedy, avg_scores_deg, avg_scores_bc, avg_scores_rand, avg_init_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 9 (right)\n",
    "\n",
    "avg_scores_greedy, avg_scores_deg, avg_scores_bc, avg_scores_rand, avg_init_scores = computeCumulativeResults(init_scores, scores_greedy, scores_deg, scores_bc, scores_rand)\n",
    "graph = 'linux'\n",
    "plotBCImprovementCumulative(graph, nodes, edges, avg_scores_greedy, avg_scores_deg, avg_scores_bc, avg_scores_rand, avg_init_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average over all graphs -- Figure 11 (left) and Figure 12 (left)\n",
    "def plotBCImprovementAllGraphs(nodes, edges, avg_scores_greedy, avg_scores_deg, avg_scores_bc, avg_scores_rand, avg_init_scores):\n",
    "    figure(figsize=(6,3))\n",
    "    x1 = array(range(0, 11))\n",
    "    labels = avg_init_scores\n",
    "    y1 = [numpy.mean([avg_init_scores[graph][0]/(nodes[graph]*nodes[graph]-edges[graph])*100 for graph in labels])]\n",
    "    y2 = [numpy.mean([avg_init_scores[graph][0]/(nodes[graph]*nodes[graph]-edges[graph])*100 for graph in labels])]\n",
    "    y3 = [numpy.mean([avg_init_scores[graph][0]/(nodes[graph]*nodes[graph]-edges[graph])*100 for graph in labels])]\n",
    "    y4 = [numpy.mean([avg_init_scores[graph][0]/(nodes[graph]*nodes[graph]-edges[graph])*100 for graph in labels])]\n",
    "    for k in range(0,10):\n",
    "        y1.append(numpy.mean([avg_scores_greedy[graph][k]/(nodes[graph]*nodes[graph]-edges[graph])*100 for graph in labels]))\n",
    "        y2.append(numpy.mean([avg_scores_deg[graph][k]/(nodes[graph]*nodes[graph]-edges[graph])*100 for graph in labels]))\n",
    "        y3.append(numpy.mean([avg_scores_bc[graph][k]/(nodes[graph]*nodes[graph]-edges[graph]-edges[graph])*100 for graph in labels]))\n",
    "        y4.append(numpy.mean([avg_scores_rand[graph][k]/(nodes[graph]*nodes[graph]-edges[graph])*100 for graph in labels]))\n",
    "    y1 = array(y1)\n",
    "    y2 = array(y2)\n",
    "    y3 = array(y3)\n",
    "    y4 = array(y4)\n",
    "    p1 = plot(x1, y1, 'ro')\n",
    "    p2 = plot(x1, y2, 'ro', color='#1B2ACC')\n",
    "    p3 = plot(x1, y3, 'ro', color='#1A2A11')\n",
    "    p4 = plot(x1, y4, 'ro', color='#AA21BB')\n",
    "    legend((p1[0], p2[0], p3[0], p4[0]), (\"Greedy\",\"Top-k Degree\", \"Top-k Betweenness\", \"Random\"), loc=\"best\")\n",
    "    #ylim(1,1.3)\n",
    "    xlabel('k')\n",
    "    ylabel('Betweenness')\n",
    "    xlim(-0.2, 10.2)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 11 (left)\n",
    "file = \"../scripts/resultsCompHeuristicsDirected.txt\"\n",
    "nodes, edges, init_scores, scores_greedy, scores_deg, scores_bc, scores_rand, init_ranks, ranks_greedy, ranks_deg, ranks_bc, ranks_rand = readDataHeuristics(file)\n",
    "avg_scores_greedy, avg_scores_deg, avg_scores_bc, avg_scores_rand, avg_init_scores = computeCumulativeResults(init_scores, scores_greedy, scores_deg, scores_bc, scores_rand)\n",
    "plotBCImprovementAllGraphs(nodes, edges, avg_scores_greedy, avg_scores_deg, avg_scores_bc, avg_scores_rand, avg_init_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 12 (left)\n",
    "# now we have to recompute everything for undirected graphs\n",
    "file = \"../scripts/resultsCompHeuristicsUndirected.txt\"\n",
    "nodes, edges, init_scores, scores_greedy, scores_deg, scores_bc, scores_rand, init_ranks, ranks_greedy, ranks_deg, ranks_bc, ranks_rand = readDataHeuristics(file)\n",
    "avg_scores_greedy, avg_scores_deg, avg_scores_bc, avg_scores_rand, avg_init_scores = computeCumulativeResults(init_scores, scores_greedy, scores_deg, scores_bc, scores_rand)\n",
    "plotBCImprovementAllGraphs(nodes, edges, avg_scores_greedy, avg_scores_deg, avg_scores_bc, avg_scores_rand, avg_init_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative results ranking: given a graph, we compute the average rank over all samples\n",
    "def computeCumulativeResultsRank(init_ranks, ranks_greedy, ranks_deg, ranks_bc, ranks_rand):\n",
    "    avg_ranks_greedy = {}\n",
    "    avg_ranks_deg = {}\n",
    "    avg_ranks_bc = {}\n",
    "    avg_ranks_rand = {}\n",
    "    avg_init_ranks = {}\n",
    "\n",
    "    for graph in ranks_greedy:\n",
    "        avg_init_ranks[graph] = []\n",
    "        avg_ranks_greedy[graph] = []\n",
    "        avg_ranks_deg[graph] = []\n",
    "        avg_ranks_bc[graph] = []\n",
    "        avg_ranks_rand[graph] = []\n",
    "        for k in range(10):\n",
    "            sumk = sum([init_ranks[graph][sample][k] for sample in range(len(ranks_greedy[graph]))])\n",
    "            sumk = sumk/float(len(ranks_greedy[graph]))\n",
    "            avg_init_ranks[graph].append(sumk)\n",
    "            sumk = sum([ranks_greedy[graph][sample][k] for sample in range(len(scores_greedy[graph]))])\n",
    "            sumk = sumk/float(len(scores_greedy[graph]))\n",
    "            avg_ranks_greedy[graph].append(sumk)\n",
    "            sumk = sum([ranks_deg[graph][sample][k] for sample in range(len(scores_greedy[graph]))])\n",
    "            sumk = sumk/float(len(scores_greedy[graph]))\n",
    "            avg_ranks_deg[graph].append(sumk)\n",
    "            sumk = sum([ranks_bc[graph][sample][k] for sample in range(len(scores_greedy[graph]))])\n",
    "            sumk = sumk/float(len(scores_greedy[graph]))\n",
    "            avg_ranks_bc[graph].append(sumk)\n",
    "            sumk = sum([ranks_rand[graph][sample][k] for sample in range(len(scores_greedy[graph]))])\n",
    "            sumk = sumk/float(len(scores_greedy[graph]))\n",
    "            avg_ranks_rand[graph].append(sumk)\n",
    "    return avg_ranks_greedy,avg_ranks_deg,avg_ranks_bc,avg_ranks_rand,avg_init_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot rank of a single node for different values of k (average over differnt samples)\n",
    "def plotRankImprovementCumulative(graph, nodes, avg_ranks_greedy,avg_ranks_deg,avg_ranks_bc,avg_ranks_rand,avg_init_ranks):\n",
    "    figure(figsize=(6,3))\n",
    "    x1 = array(range(0, 11))\n",
    "    y1 = array([avg_init_ranks[graph][0]]+avg_ranks_greedy[graph])\n",
    "    y2 = array([avg_init_ranks[graph][0]]+avg_ranks_deg[graph])\n",
    "    y3 = array([avg_init_ranks[graph][0]]+avg_ranks_bc[graph])\n",
    "    y4 = array([avg_init_ranks[graph][0]]+avg_ranks_rand[graph])\n",
    "    y1 = [score/nodes[graph]*100 for score in y1]\n",
    "    y2 = [score/nodes[graph]*100 for score in y2]\n",
    "    y3 = [score/nodes[graph]*100 for score in y3]\n",
    "    y4 = [score/nodes[graph]*100 for score in y4]\n",
    "\n",
    "    p1 = plot(x1, y1, 'ro')\n",
    "    p2 = plot(x1, y2, 'ro', color='#1B2ACC')\n",
    "    p3 = plot(x1, y3, 'ro', color='#1A2A11')\n",
    "    p4 = plot(x1, y4, 'ro', color='#AA21BB')\n",
    "    legend((p1[0], p2[0], p3[0], p4[0]), (\"Greedy\",\"Top-k Degree\", \"Top-k Betweenness\", \"Random\"), loc=\"best\")\n",
    "    xlabel('k')\n",
    "    xlim(-0.2, 10.2)\n",
    "    ylabel('Rank')\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 10 (left)\n",
    "file = \"../scripts/resultsCompHeuristicsDirected.txt\"\n",
    "nodes, edges, init_scores, scores_greedy, scores_deg, scores_bc, scores_rand, init_ranks, ranks_greedy, ranks_deg, ranks_bc, ranks_rand = readDataHeuristics(file)\n",
    "avg_ranks_greedy,avg_ranks_deg,avg_ranks_bc,avg_ranks_rand,avg_init_ranks = computeCumulativeResultsRank(init_ranks, ranks_greedy, ranks_deg, ranks_bc, ranks_rand)\n",
    "graph = 'munmun_digg_reply'\n",
    "plotRankImprovementCumulative(graph, nodes, avg_ranks_greedy,avg_ranks_deg,avg_ranks_bc,avg_ranks_rand,avg_init_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 10 (right)\n",
    "file = \"../scripts/resultsCompHeuristicsDirected.txt\"\n",
    "nodes, edges, init_scores, scores_greedy, scores_deg, scores_bc, scores_rand, init_ranks, ranks_greedy, ranks_deg, ranks_bc, ranks_rand = readDataHeuristics(file)\n",
    "avg_ranks_greedy,avg_ranks_deg,avg_ranks_bc,avg_ranks_rand,avg_init_ranks = computeCumulativeResultsRank(init_ranks, ranks_greedy, ranks_deg, ranks_bc, ranks_rand)\n",
    "graph = 'linux'\n",
    "plotRankImprovementCumulative(graph, nodes, avg_ranks_greedy,avg_ranks_deg,avg_ranks_bc,avg_ranks_rand,avg_init_ranks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average ranking over all graphs -- Figure 11 (right) and Figure 12 (right)\n",
    "def plotRankImprovementAllGraphs(nodes, edges, avg_ranks_greedy,avg_ranks_deg,avg_ranks_bc,avg_ranks_rand,avg_init_ranks):\n",
    "    figure(figsize=(6,3))\n",
    "    x1 = array(range(0, 11))\n",
    "    labels = nodes\n",
    "    y1 = [numpy.mean([avg_init_ranks[graph][0]/nodes[graph]*100 for graph in labels])]\n",
    "    y2 = [numpy.mean([avg_init_ranks[graph][0]/nodes[graph]*100 for graph in labels])]\n",
    "    y3 = [numpy.mean([avg_init_ranks[graph][0]/nodes[graph]*100 for graph in labels])]\n",
    "    y4 = [numpy.mean([avg_init_ranks[graph][0]/nodes[graph]*100 for graph in labels])]\n",
    "    for k in range(0,10):\n",
    "        y1.append(numpy.mean([avg_ranks_greedy[graph][k]/nodes[graph]*100 for graph in labels]))\n",
    "        y2.append(numpy.mean([avg_ranks_deg[graph][k]/nodes[graph]*100 for graph in labels]))\n",
    "        y3.append(numpy.mean([avg_ranks_bc[graph][k]/nodes[graph]*100 for graph in labels]))\n",
    "        y4.append(numpy.mean([avg_ranks_rand[graph][k]/nodes[graph]*100 for graph in labels]))\n",
    "\n",
    "    y1 = array(y1)\n",
    "    y2 = array(y2)\n",
    "    y3 = array(y3)\n",
    "    y4 = array(y4)\n",
    "    p1 = plot(x1, y1, 'ro')\n",
    "    p2 = plot(x1, y2, 'ro', color='#1B2ACC')\n",
    "    p3 = plot(x1, y3, 'ro', color='#1A2A11')\n",
    "    p4 = plot(x1, y4, 'ro', color='#AA21BB')\n",
    "    legend((p1[0], p2[0], p3[0], p4[0]), (\"Greedy\",\"Top-k Degree\", \"Top-k Betweenness\", \"Random\"), loc=\"best\")\n",
    "    xlabel('k')\n",
    "    xlim(-0.2, 10.2)\n",
    "    ylabel('Rank')\n",
    "\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 11 (right)\n",
    "file = \"../scripts/resultsCompHeuristicsDirected.txt\"\n",
    "nodes, edges, init_scores, scores_greedy, scores_deg, scores_bc, scores_rand, init_ranks, ranks_greedy, ranks_deg, ranks_bc, ranks_rand = readDataHeuristics(file)\n",
    "avg_ranks_greedy,avg_ranks_deg,avg_ranks_bc,avg_ranks_rand,avg_init_ranks = computeCumulativeResultsRank(init_ranks, ranks_greedy, ranks_deg, ranks_bc, ranks_rand)\n",
    "plotRankImprovementAllGraphs(nodes, edges, avg_ranks_greedy,avg_ranks_deg,avg_ranks_bc,avg_ranks_rand,avg_init_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 12 (right)\n",
    "file = \"../scripts/resultsCompHeuristicsUndirected.txt\"\n",
    "nodes, edges, init_scores, scores_greedy, scores_deg, scores_bc, scores_rand, init_ranks, ranks_greedy, ranks_deg, ranks_bc, ranks_rand = readDataHeuristics(file)\n",
    "avg_ranks_greedy,avg_ranks_deg,avg_ranks_bc,avg_ranks_rand,avg_init_ranks = computeCumulativeResultsRank(init_ranks, ranks_greedy, ranks_deg, ranks_bc, ranks_rand)\n",
    "plotRankImprovementAllGraphs(nodes, edges, avg_ranks_greedy,avg_ranks_deg,avg_ranks_bc,avg_ranks_rand,avg_init_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
